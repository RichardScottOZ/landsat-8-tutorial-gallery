{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landsat-8 on AWS\n",
    "\n",
    "* **How can I efficiently find, visualize, and analyze a large set of Landsat-8 imagery on AWS?**\n",
    "\n",
    "We will examine raster images from the [Landsat-8 instrument](https://www.usgs.gov/land-resources/nli/landsat). The Landsat program is the longest-running civilian satellite imagery program, with the first satellite launched in 1972 by the US Geological Survey. Landsat 8 is the latest satellite in this program, and was launched in 2013. Landsat observations are processed into “scenes”, each of which is approximately 183 km x 170 km, with a spatial resolution of 30 meters and a temporal resolution of 16 days. The duration of the landsat program makes it an attractive source of medium-scale imagery for land surface change analyses.\n",
    "\n",
    "This notebook is a simplified update of a [blog post written in October 2018](https://medium.com/pangeo/cloud-native-geoprocessing-of-earth-observation-satellite-data-with-pangeo-997692d91ca2), highlighting the integration of several modern Python libraries: [satsearch](https://github.com/sat-utils/sat-search), [intake-stac](https://github.com/intake/intake-stac), [geopandas](https://github.com/geopandas/geopandas), [xarray](https://github.com/pydata/xarray),  [dask](https://github.com/dask/dask), [holoviz](https://holoviz.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding data on the Cloud \n",
    "\n",
    "Finding geospatial data on the Cloud has been difficult until recent years. Earth scientists are accustomed to going to specific portals to find data, for example [NASA's Earthdata Search](https://search.earthdata.nasa.gov), ESA's Copernicus Hub (https://scihub.copernicus.eu), USGS National Map (https://www.usgs.gov/core-science-systems/national-geospatial-program/national-map). AWS has had a registry of open datasets stored on AWS for many years now https://aws.amazon.com/opendata/public-datasets/.  Earth-science specific data is also listed here - https://aws.amazon.com/earth/. But what if you want to search for Landsat8 data over an area of interest? Browsing through lists of files is cumbersome. \n",
    "\n",
    "An effort is underway to make geospatial data on the Cloud more easy to discover by having a bare-bones web-friendly and search-friendly metadata catalog standard: The SpatioTemporal Asset Catalog (STAC). Once the standard is set, many tools can co-exist to build upon it. For example https://www.element84.com/earth-search/ allows us to programmatically and visually search for data on AWS! Here we will use the [satsearch Python library](https://github.com/sat-utils/sat-search) for searching Landsat8 on AWS. Note you could also search for Sentinel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress library deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import satsearch\n",
    "print(satsearch.__version__)\n",
    "print(satsearch.config.API_URL)\n",
    "from satsearch import Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE this STAC API endpoint does not currently search the entire catalog\n",
    "\n",
    "bbox = (-124.71, 45.47, -116.78, 48.93) #(west, south, east, north) \n",
    "\n",
    "timeRange = '2019-01-01/2020-10-01'\n",
    "\n",
    "# STAC metadata properties\n",
    "properties =  ['eo:row=027',\n",
    "               'eo:column=047',\n",
    "               'landsat:tier=T1'] \n",
    "\n",
    "results = Search.search(collection='landsat-8-l1', \n",
    "                        bbox=bbox,\n",
    "                        datetime=timeRange,\n",
    "                        property=properties,\n",
    "                        sort=['<datetime'],\n",
    "                        )\n",
    "\n",
    "print('%s items' % results.found())\n",
    "items = results.items()\n",
    "items.save('subset.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that it is easy to load geojson with geopandas!\n",
    "import geopandas as gpd\n",
    "\n",
    "gf = gpd.read_file('subset.geojson')\n",
    "gf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidy display of band information from the 'eo:bands column'\n",
    "import ast\n",
    "import pandas as pd\n",
    "band_info = pd.DataFrame(ast.literal_eval(gf.iloc[0]['eo:bands']))\n",
    "band_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot search AOI and frames on a map using Holoviz Libraries (more on these later)\n",
    "import geoviews as gv\n",
    "import hvplot.pandas\n",
    "\n",
    "cols = gf.loc[:,('id','eo:row','eo:column','geometry')]\n",
    "\n",
    "footprints = cols.hvplot(geo=True, line_color='k', hover_cols=['eo:row','eo:column'], alpha=0.1, title='Landsat 8 T1')\n",
    "tiles = gv.tile_sources.CartoEco.options(width=700, height=500) \n",
    "labels = gv.tile_sources.StamenLabels.options(level='annotation')\n",
    "tiles * footprints * labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ipywidgets\n",
    "\n",
    "[ipywidgets](https://ipywidgets.readthedocs.io/en/latest/) provide another convenient approach to custom visualizations within JupyterLab. The function below allows us to browse through all the image thumbnails for a group of images (more specifically a specific Landsat8 path and row). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from IPython.display import display, Image\n",
    "\n",
    "def browse_images(items):\n",
    "    n = len(items)\n",
    "\n",
    "    def view_image(i=0):\n",
    "        item = items[i]\n",
    "        print(f\"id={item.id}\\tdate={item.datetime}\\tcloud%={item['eo:cloud_cover']}\")\n",
    "        display(Image(item.asset('thumbnail')['href']))\n",
    "    \n",
    "    interact(view_image, i=(0,n-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browse_images(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intake-STAC\n",
    "\n",
    "the intake-stac library allows us to easily load these scenes described with STAC metadata into xarray DataArrays! NOTE this library is very new and will likely undergo changes in the near future. https://github.com/pangeo-data/intake-stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you've installed intake-STAC, it will automatically import alongside intake\n",
    "import intake\n",
    "catalog = intake.open_stac_item_collection(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sceneid = 'LC80470272019096'\n",
    "catalog[sceneid]['B2'].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's work with the Geotiffs using Xarray\n",
    "# NOTE that you don't have to specify the URL or filePath!\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "item = catalog[sceneid]\n",
    "da = item['B2'].to_dask()\n",
    "da.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask Chunks and Cloud Optimized Geotiffs\n",
    "\n",
    "Since we didn't specify chunk sizes, everything is read as one chunk. When we load larger sets of imagery\n",
    "we can change these chunk sizes to use dask. It's best to align dask chunks with the way image chunks (typically called \"tiles\" are stored on disk or cloud storage buckets. The landsat data is stored on AWS S3 in a tiled Geotiff format where tiles are 512x512, so we should pick som multiple of that, and typically aim for chunksizes of ~100Mb (although this is subjective). You can read more about dask chunks here: https://docs.dask.org/en/latest/array-best-practices.html\n",
    "\n",
    "Also check out this documentation about the Cloud-optimized Geotiff format, it is an excellent choice for putting satellite raster data on Cloud storage: https://www.cogeo.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intake-STAC Item to chunked dask array\n",
    "da = item.B2(chunks=dict(band=1, x=2048, y=2048)).to_dask()\n",
    "da.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load all the bands into an xarray dataset!\n",
    "# Stick to bands that have the same Ground Sample Distance for simplicity\n",
    "bands = band_info.query('gsd == 30').common_name.to_list()\n",
    "bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = item.stack_bands(bands)\n",
    "da = stacked(chunks=dict(band=1, x=2048, y=2048)).to_dask()\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want we can convert this to an xarray dataset, with variable names corresponding to common names\n",
    "# This is all very fast because we are only reading metadata\n",
    "da['band'] = bands\n",
    "ds = da.to_dataset(dim='band')\n",
    "print('Dataset size: [Gb]', ds.nbytes/1e9)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computations or visualizations trigger the streaming of bytes from S3 into memory\n",
    "# Here we will compute the mean for a number of pixels for a box defined by easting and northings\n",
    "zonal_mean = ds['nir'].sel(x=slice(4.99e5, 5.03e5), y=slice(5.244e6, 5.238e6)).mean()\n",
    "zonal_mean.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hvplot\n",
    "\n",
    "HoloViz is a coordinated effort to make browser-based data visualization in Python easier to use, easier to learn, and more powerful! https://holoviz.org One particularly powerful library is `hvplot`, which allows for interactive visualizations of pandas dataframes or xarray DataArrays. With this tool you pull data on-the-fly only as required by zoom level and band selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "\n",
    "da.hvplot.image(groupby='band', rasterize=True, dynamic=True, cmap='magma',\n",
    "                width=700, height=500,  widget_location='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask-Gateway Cluster\n",
    "\n",
    "If we don't specify a specific cluster, dask will use the cores on the machine we are running our notebook on instead, lets connect to a Dask-Gateway cluster. You can read more about this cluster at https://gateway.dask.org/. **It can take a few minutes for the cluster to become ready for computing. This is because EC2 machines are being created for you behind the scenes**. Monitor the 'Dashboard' link to see cluster activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import GatewayCluster\n",
    "from distributed import Client\n",
    "\n",
    "cluster = GatewayCluster()\n",
    "cluster.adapt(minimum=2, maximum=20) #Keep a minimum of 2 workers, but allow for scaling up to 20 if there is RAM and CPU pressure\n",
    "client = Client(cluster) #Make sure dask knows to use this cluster for computations\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# First let's construct a large dataset with all the scenes in our search so that we\n",
    "# have a time dimension\n",
    "# Loop through geopandas geodataframe (each row is a STAC ITEM)\n",
    "import dask\n",
    "\n",
    "@dask.delayed\n",
    "def stacitem_to_dataset(item):\n",
    "    print(item.id)\n",
    "    stacked = catalog[item.id].stack_bands(bands)\n",
    "    da = stacked(chunks=dict(band=1, x=8000, y=2048)).to_dask()\n",
    "    da['band'] = bands # use common names\n",
    "    da = da.expand_dims(time=[pd.to_datetime(item.datetime)])\n",
    "    ds = da.to_dataset(dim='band')\n",
    "    return ds\n",
    "\n",
    "lazy_datasets = []\n",
    "for i,item in gf.iterrows():\n",
    "    ds = stacitem_to_dataset(item)\n",
    "    lazy_datasets.append(ds)\n",
    "    \n",
    "datasets = dask.compute(*lazy_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = xr.concat(datasets, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset size: [Gb]', DS.nbytes/1e9)\n",
    "DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed computations\n",
    "\n",
    "We'll calculate the classic NDVI index with all our data\n",
    "\n",
    "NOTE that you should be using Landsat ARD data (https://www.usgs.gov/land-resources/nli/landsat/us-landsat-analysis-ready-data) for this with atmospheric corrections! \n",
    "this is just to illustrate the intuitive syntax of xarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI = (DS['nir'] - DS['red']) / (DS['nir'] + DS['red'])\n",
    "NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on distributed versus local memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndvi_my_memory = NDVI.compute() # compute pulls computation results into notebook process\n",
    "NDVI = NDVI.persist() # persist keeps computation results on the dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting pulls data from distributed cluster memory on-demand\n",
    "NDVI.hvplot.image(groupby='time', x='x',y='y', \n",
    "                  cmap='BrBG', clim=(-1,1),\n",
    "                  rasterize=True, dynamic=True, \n",
    "                  width=700, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a subset and save as a netcdf file\n",
    "sub = NDVI.sel(x=slice(4.5e5,5.0e5), y=slice(5.25e6,5.2e6)).mean(dim=['time'])\n",
    "sub.hvplot.image(rasterize=True, dynamic=True, width=700, height=500, cmap='greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myda = sub.compute() #pull subset to local memory first, some formats allow distributed writing too\n",
    "myda.to_netcdf(path='myndvi.nc', engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_trip = xr.load_dataarray('myndvi.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be a good citizen and always explicitly shut down computing resources when you're not using them!\n",
    "# client.close()\n",
    "# cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
